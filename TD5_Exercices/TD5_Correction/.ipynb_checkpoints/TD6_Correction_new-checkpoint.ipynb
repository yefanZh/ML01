{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML01 : TD5 - Premiers classifieurs discriminatifs linéaires\n",
    "\n",
    "Réalisé par Cyprien Gilet et Khaled Belahcene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import scipy.stats as stats\n",
    "\n",
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implémentation fonctions d'évaluation de performances\n",
    "\n",
    "- Pour chaque observation $i \\in \\{1,\\dots,n\\}$, $Y_i$ caractérisera la variable aléatoire décrivant la classe de l'observation $i$.\n",
    "- Pour chaque observation $i \\in \\{1,\\dots,n\\}$, $X_i = [X_{i1},\\dots,X_{id}]$ caractérisera le vecteur aléatoire décrivant le profile de l'observation $i$, composés de $d$ variables descriptives.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.** Implémenter une fonction *perceptron_predict(W,X)* permettant d'attribuer une classe $\\hat{Y}_i$ à chaque observation $X_{i} = [X_{i1},\\dots,X_{id}]$ à partir d'un vecteur de poids $W= [w_0,\\dots,w_d]\\in\\mathbb{R}^{d+1}$ donné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÉPONSE À LA QUESTION 1.1 :\n",
    "\n",
    "def perceptron_predict(W,X):\n",
    "    n = np.shape(X)[0]\n",
    "    Yhat = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        Zi = np.concatenate([np.ones(1), X[i,:]])\n",
    "        Yhat[i] = np.sign(np.dot(W,Zi))\n",
    "    return Yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.  Apprentissage et algorithm du classifieur Perceptron.\n",
    "\n",
    "Calibrer le classifieur Perceptron à partir d'une base d'apprentissage revient à calculer les poids $W= [w_0,\\dots,w_d]\\in\\mathbb{R}^{d+1}$ permettant de séparer linéarement au mieux les observations de classe $1$ de celles de la classe $-1$. Pour ce faire, nous pouvons considérer l'algorithme du perceptron proposé par Rosenblatt :\n",
    "\n",
    "- **Input:** Base d'apprentissage $\\mathcal{S} = \\{(Y_i,X_i), i=1\\dots,n\\}$\n",
    "- Initialiser $W$\n",
    "- Tant qu'il y a des erreurs de prediction\n",
    "    - for $i=1,\\dots,n$\n",
    "        - $\\hat{Y}_i = \\mathrm{Sign}\\left(w_0 + \\sum_{j=1}^d w_j X_{ij}\\right)$\n",
    "        - if $\\hat{Y}_i * Y_i < 0$ :\n",
    "            - $W \\leftarrow W + Y_i \\times [1, X_{i1}, \\dots, X_{id}]$\n",
    "            \n",
    "- **Return:** $W$    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.  Exemple avec 2 variables descriptives et 3 observations.\n",
    "\n",
    "On se place dans un contexte simple où $d=2$ variables descriptives et $n=3$ observations, tel que :\n",
    "\n",
    "- $X_1 =[1,3]$ et $Y_1 = -1$\n",
    "- $X_2 =[2,2]$ et $Y_1 = -1$\n",
    "- $X_3 =[1,1]$ et $Y_1 = +1$\n",
    "\n",
    "Dans le contexte où l'on a $d=2$ variables descriptives, la frontière de décision sera une droite d'équation\n",
    "\\begin{equation}\n",
    "\\mathcal{D} = \\left\\{(x_1,x_2) : w_0 + w_1 x_1 + w_2 x_2 = 0\\right\\}.\n",
    "\\end{equation}\n",
    "\n",
    "**Question 1.2.1.** Représenter les trois points $X_1,X_2,X_3$ sur une feuille de sorte que l'on visualise leur apportenance à chaque classe.\n",
    "\n",
    "**Question 1.2.2.** Supposons que l'on ait initialisé $W = [0.5,2,-1]$, tracer la frontière de décision $\\mathcal{D}$ sur cette même figure.\n",
    "\n",
    "**Question 1.2.3.** Appliquer l'algorithme ci-dessus permettant d'ajuster la frontière de décision et mettre à jour la figure à chaque itération."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÉPONSE À LA QUESTION 1.2.1 :\n",
    "\n",
    "np.random.seed(407)\n",
    "\n",
    "d = 2\n",
    "n1 = 2 \n",
    "n2 = 1\n",
    "n = n1+n2\n",
    "\n",
    "XTrain = np.zeros((n,d))\n",
    "XTrain[0,0] = 1\n",
    "XTrain[0,1] = 3\n",
    "XTrain[1,0] = 2\n",
    "XTrain[1,1] = 2\n",
    "XTrain[2,0] = 1\n",
    "XTrain[2,1] = 1\n",
    "YTrain = np.r_[-np.ones((n1,1)), np.ones((n2,1))].ravel()\n",
    "\n",
    "figScatter = plt.figure(figsize=(6,6))\n",
    "ax1 = figScatter.add_subplot(1,1,1)\n",
    "ax1.scatter(XTrain[np.where(YTrain==-1),0], XTrain[np.where(YTrain==-1),1], color='purple', marker='*', label='Classe -1',s=250)\n",
    "ax1.scatter(XTrain[np.where(YTrain==1),0], XTrain[np.where(YTrain==1),1], color='orange', marker='*', label='Classe 1',s=250)\n",
    "ax1.legend(fontsize=20, loc='upper right')\n",
    "ax1.set_xlabel(\"$X_1$\",fontsize=20)\n",
    "ax1.set_ylabel(\"$X_2$\",fontsize=20)\n",
    "ax1.set_xlim([0,4])\n",
    "ax1.set_ylim([-1,5])\n",
    "ax1.set_title(\"Scatter plot of the Training set\",fontsize=20)\n",
    "ax1.tick_params(axis='x', labelsize=20)\n",
    "ax1.tick_params(axis='y', labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÉPONSE AUX QUESTIONs 1.2.2 et 1.2.3 :\n",
    "\n",
    "W = np.zeros(d+1)\n",
    "W[0] = 0.5\n",
    "W[1] = 2\n",
    "W[2] = -1\n",
    "print('W init =', W)\n",
    "\n",
    "yhat = np.zeros(n)\n",
    "T = 3\n",
    "\n",
    "# fonction affichage de la frontière de décision :\n",
    "def qet_BoundarieLine_2D(W,xx1):\n",
    "    xx2 = (W[0] + W[1]*xx1)/(-W[2])\n",
    "    return xx2\n",
    "\n",
    "\n",
    "# Plot figure :\n",
    "figScatter = plt.figure(figsize=(20,20))\n",
    "plt.gcf().subplots_adjust(hspace=0.25)\n",
    "ax_ind = 0\n",
    "\n",
    "xx1 = np.linspace(0,4,100)\n",
    "xx2 = qet_BoundarieLine_2D(W,xx1)\n",
    "\n",
    "nn = 100\n",
    "X1_min, X1_max = 0, 4\n",
    "X2_min, X2_max = -1, 5\n",
    "XX1, XX2 = np.meshgrid(np.linspace(X1_min, X1_max, nn), np.linspace(X2_min, X2_max, nn))\n",
    "\n",
    "\n",
    "for t in range(T):\n",
    "    \n",
    "    for i in range(n):\n",
    "        \n",
    "        ax_ind = ax_ind + 1\n",
    "        axi = figScatter.add_subplot(T,n,ax_ind)\n",
    "        axi.plot(xx1,xx2,'--', color='blue')\n",
    "        \n",
    "        Ai = np.concatenate([np.ones(1), XTrain[i,:]])\n",
    "        yhat[i] = np.sign(np.dot(W,Ai))\n",
    "        if YTrain[i]*yhat[i] <=0 :\n",
    "            W = W + YTrain[i] * Ai\n",
    "            yhat[i] = np.sign(np.dot(W,Ai))\n",
    "        \n",
    "        Z_spct = perceptron_predict(W,np.c_[XX1.ravel(), XX2.ravel()])\n",
    "        Z_spct = Z_spct.reshape(XX1.shape)\n",
    "        out = axi.contourf(XX1, XX2, Z_spct, alpha=0.15)\n",
    "        xx1 = np.linspace(0,4,100)\n",
    "        xx2 = qet_BoundarieLine_2D(W,xx1)\n",
    "        axi.scatter(XTrain[np.where(YTrain==-1),0], XTrain[np.where(YTrain==-1),1], color='purple', marker='*', label='Classe -1',s=250, alpha=0.3)\n",
    "        axi.scatter(XTrain[np.where(YTrain==1),0], XTrain[np.where(YTrain==1),1], color='orange', marker='*', label='Classe 1',s=250, alpha=0.3)\n",
    "        if YTrain[i]==-1:\n",
    "            axi.scatter(XTrain[i,0], XTrain[i,1], color='purple', marker='*', label='Selected point',s=250)\n",
    "        if YTrain[i]==1:\n",
    "            axi.scatter(XTrain[i,0], XTrain[i,1], color='orange', marker='*', label='Selected point',s=250)\n",
    "        axi.plot(xx1,xx2, color='blue')\n",
    "        axi.legend(fontsize=20, loc='upper right')\n",
    "        axi.set_xlabel(\"$X_1$\",fontsize=20)\n",
    "        axi.set_ylabel(\"$X_2$\",fontsize=20)\n",
    "        axi.set_xlim([0,4])\n",
    "        axi.set_ylim([-1,5])\n",
    "        titlestring = \"m = \"+str(t)+\", i = \"+str(i+1)+\", W = \"+str(W)\n",
    "        axi.set_title(titlestring,fontsize=20)\n",
    "        axi.tick_params(axis='x', labelsize=20)\n",
    "        axi.tick_params(axis='y', labelsize=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.  Classifieur maximisant la marge\n",
    "\n",
    "Lorsque les données sont *linéairement séparables*, on peut chercher, parmi toutes les règles de décisions linéaires qui séparent les points de l'ensemble d'apprentissage, celle qui produit la frontière de décision -- l'*hyperplan séparateur*-- le plus éloigné des points d'apprentissage.\n",
    "- **Cas de deux points :** quel est l'hyperplan séparateur de marge maximale permettant de séparer $X^+$ et $X^-$ ? Application au cas précédent avec $d=2$ $X^+=\\{(1,1)\\}$ et $X^-_1=\\{(2,4)\\}$ : déterminer à la main la règle de décision de marge maximale, et visualiser la frontière de décision correspondante.\n",
    "- **Cas avec trois points :**\n",
    "    * Avec $X^-_2=\\{(2,4), (1,5)\\}$, montrer que la règle de décision déterminée précédemment reste inchangée. La frontière est uniquement déterminée par les points (1,1) et (2,4), pour lesquels on dit que *la contrainte de marge est saturée*, et on parle de *vecteurs de support*.\n",
    "    * Montrer qu'il n'en est pas de même avec $X^-_3=\\{(2,4), (1,5), (0,4)\\}$. Quels sont les vecteurs de support ?\n",
    "- **En général :** On peut trouver le séparateur de plus grande marge en résolvant le problème d'optimisation vu en cours, ou une formulation équivalente alternative (il en existe de nombreuses, avec leurs qualités et leurs défauts). Nous verrons par la suite un algorithme de *descente de gradient* permettant de le déterminer. On peut aussi utiliser l'une des implémentations proposée par scikit-learn (avec `svm.SVC(kernel='linear')` ).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correction section 2.\n",
    "- Dans le cas de deux points, l'hyperplan séparateur de marge maximale est l'hyperplan médiateur (preuve inutile ici : on peut montrer que la somme des marges relatives à chaque point est inférieure à la distance entre les points en considérant les deux boules centrées sur les points, de rayon la marge correspondante, qui sont tangents à l'hyperplan séparateur, ce qui n'est possible que si ces boules sont disjointes ou tangentes). \n",
    "    Pour les points donnés, la médiatrice $\\Delta$ est normale au vecteur $\\arrow(X_2,X_1) = [1 ; 3 ]$ et passe par le milieu $M$ de $[X_1,X_2] = [1.5 , 2.5]$. Elle a pour équation cartésienne $x+3y + 9= 0$. Le cours préconise d'utiliser la règle de décision \n",
    "    $$\n",
    "    f_\\Delta((x,y)) = \\frac{-1}{\\sqrt{10}} x - \\frac{3}{\\sqrt{10}} y + \\frac{9}{\\sqrt{10}},\n",
    "    $$\n",
    "    dont :\n",
    "    * le signe correspond à celui des classes,\n",
    "    * la valeur absolue correspond à la marge (la distance entre la frontière de décision et le plus proche des points de l'ensemble d'apprentissage).\n",
    "    Géométriquement, la marge est  $\\|X_1,M\\|_2= \\frac{1}{2} \\|X_1,X_2\\|=\\frac{\\sqrt{10}}{2}$. On vérifie que $f((1,1))=\\frac{5}{\\sqrt{10}}=\\frac{\\sqrt{10}}{2}$ et $f((2,4))=\\frac{-5}{\\sqrt{10}}$.\n",
    "\n",
    "- Le problème $max\\_margin(X^+,X^-_2)$ est plus contraint que $max\\_margin(X^+,X^-_1)$, donc la valeur de sa solution est inférieure ou égale - autrement dit, on ne peut pas espérer améliorer la performance de $\\Delta$. Par ailleurs, on va voir que $\\Delta$ reste un classifieur valide de marge $\\frac{5}{\\sqrt{10}}$ :\n",
    "    $f_\\Delta((1,5)) = -7/\\sqrt{10}$ donc le point $(1,5)$ est situé du bon côté de $\\Delta$ (côté négatif) et à une distance $7/\\sqrt{10}$ supérieure à $5/\\sqrt{10}$, donc la marge de $\\Delta$ reste inchangée.\n",
    "    Finalement, $f_\\Delta$ reste un classifieur optimal pour $X^+, X^-_2$.\n",
    "    \n",
    "    $f_\\Delta((0,4)) = -3/\\sqrt{10}$ : le point $(1,1)$ est correctement classé par $f_\\Delta$, mais dégrade la marge. On peut trouver un meilleur classifieur dont le support est $(1,1):+, (2,4):-, (0,4):-$. Les deux points de la classe $-$ sont sur une ligne de niveau de $f$ donc $f$ est une droite parallèle à $(2,4), (0,4)$ (horizontale donc), et à mi distance entre ces deux points et $(1,1)$, c'est donc $f_{\\Delta'} = -y+2.5$ et on vérifie :\n",
    "    $f_{\\Delta'}((1,1)) = 1.5, f_{\\Delta'}((2,4)) = -1.5, f_{\\Delta'}((0,5)) = -2.5, f_{\\Delta'}((0,4)) = -1.5$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.  Comparaison Classifieurs Perceptron et SVM :\n",
    "\n",
    "On se place dans un contexte simple où $d=2$ variables descriptives tel que :\n",
    "\n",
    "- $n=100$ observations telles que $n_1 = 50$ observations appartiendront à la classe $1$ et $n_2 = 50$ observations à la classe $-1$.\n",
    "- Pour chaque observation $i \\in \\{1,\\dots,n\\}$, $Y_i$ caractérisera la variable aléatoire décrivant la classe de l'observation $i$.\n",
    "- Pour chaque observation $i \\in \\{1,\\dots,n\\}$, $X_i = [X_{i1},X_{i2}]$ sera généré de la façon suivante\n",
    "\n",
    "    \\begin{equation}\n",
    "    X_i \\sim \\mathcal{N}\\left(\\mu_1, \\Sigma_1 \\right) \\; \\text{si} \\; Y_i = -1 \\quad\\quad \\text{et} \\quad\\quad  X_i \\sim \\mathcal{N}\\left(\\mu_2, \\Sigma_2 \\right) \\; \\text{si} \\; Y_i = 1.\n",
    "    \\end{equation}\n",
    "    où\n",
    "    \\begin{equation}\n",
    "        \\mu_1 = [0, 0], \\quad \\mu_2 = [6, 7], \\quad \n",
    "        \\Sigma_1 = \\begin{bmatrix}\n",
    "                 2 & 1 \\\\ \n",
    "                 1 & 3\n",
    "                \\end{bmatrix}, \\quad \n",
    "        \\Sigma_2 = \\begin{bmatrix}\n",
    "                 6 & -3 \\\\ \n",
    "                 -3 & 3.5\n",
    "                \\end{bmatrix},  \n",
    "    \\end{equation}\n",
    "\n",
    "**Question 3.1.** À l'aide du TD4, représenter le scatter plot de cette base de données.\n",
    "\n",
    "**Question 3.2.** Implémenter une fonction *fit_perceptron(XTrain,YTrain,T)* permettant de calibrer le classifieur Perceptron sur une base d'apprentissage à partir de l'algorithme décrit dans la Section 1.1. On fera en sorte que pour chaque itération cet algorithme stock dans un tableau la proportion d'erreur de prédiction sur la base d'apprentissage de sorte à pouvoir analiser la convergence de l'algorithme.\n",
    "\n",
    "**Question 3.3.** Calibrer le classifieur Perceptron sur cette base de données simulée et tracer la convergence du taux d'erreur en fonction des itérations.\n",
    "\n",
    "**Question 3.4.** Calibrer le classifieur SVM sur cette base de données en utilisant la fonction Scikit-Learn  `svm.SVC(kernel='linear')`. Quel est le taux d'erreurs global sur cette base d'apprentissage ?\n",
    "\n",
    "**Question 3.4.** Afficher sur le scatter plot les frontière de décisions obtenue par chaque classifieur en vous inspirant du TD4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÉPONSE À LA QUESTION 3.1 :\n",
    "np.random.seed(407)\n",
    "\n",
    "d = 2\n",
    "n1 = 50 \n",
    "n2 = 50\n",
    "n = n1+n2\n",
    "mu1 = [0, 0]\n",
    "mu2 = [6, 7]\n",
    "Cov1 = np.array([[4, 0], [0, 1]])\n",
    "Cov2 = np.array([[6, -3], [-3, 3.5]])\n",
    "rng = np.random.default_rng()\n",
    "XTrain = np.r_[rng.multivariate_normal(mu1, Cov1, size=n1), rng.multivariate_normal(mu2, Cov2, size=n2)]\n",
    "YTrain = np.r_[-np.ones((n1,1)), np.ones((n2,1))].ravel()\n",
    "\n",
    "figScatter = plt.figure(figsize=(6,6))\n",
    "ax1 = figScatter.add_subplot(1,1,1)\n",
    "ax1.scatter(XTrain[np.where(YTrain==-1),0], XTrain[np.where(YTrain==-1),1], color='purple', marker='.', label='C-1',s=150)\n",
    "ax1.scatter(XTrain[np.where(YTrain==1),0], XTrain[np.where(YTrain==1),1], color='orange', marker='.', label='C1',s=150)\n",
    "ax1.legend(fontsize=20, loc='upper right')\n",
    "ax1.set_xlabel(\"$X_1$\",fontsize=20)\n",
    "ax1.set_ylabel(\"$X_2$\",fontsize=20)\n",
    "ax1.set_xlim([-6,14])\n",
    "ax1.set_ylim([-3,12])\n",
    "ax1.set_title(\"Scatter plot of the Training set\",fontsize=20)\n",
    "ax1.tick_params(axis='x', labelsize=20)\n",
    "ax1.tick_params(axis='y', labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÉPONSE À LA QUESTION 3.2 :\n",
    "\n",
    "def fit_perceptron(XTrain,YTrain,T):\n",
    "    n = np.shape(XTrain)[0]\n",
    "    d = np.shape(XTrain)[1]\n",
    "    W = np.zeros(d+1)\n",
    "\n",
    "    stock_err = np.zeros(T*n)\n",
    "    iteration = 0\n",
    "\n",
    "    for t in range(T):\n",
    "\n",
    "        for i in range(n):\n",
    "            \n",
    "            yhat = perceptron_predict(W,XTrain)\n",
    "            stock_err[iteration] = np.mean(yhat!=YTrain)\n",
    "            \n",
    "            Ai = np.concatenate([np.ones(1), XTrain[i,:]])\n",
    "            if YTrain[i]*yhat[i] <=0 :\n",
    "                W = W + YTrain[i] * Ai\n",
    "                \n",
    "            iteration = iteration + 1\n",
    "            \n",
    "    return W, stock_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÉPONSE À LA QUESTION 3.3 :\n",
    "W, stock_err = fit_perceptron(XTrain,YTrain,6)\n",
    "figConv = plt.figure(figsize=(6,6))\n",
    "ax1 = figConv.add_subplot(1,1,1)\n",
    "ax1.plot(stock_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÉPONSE À LA QUESTION 3.4 :\n",
    "from sklearn import svm\n",
    "SVMclf = svm.SVC(kernel='linear')\n",
    "SVMclf.fit(XTrain, YTrain)\n",
    "YhatSVM = SVMclf.predict(XTrain)\n",
    "err_SVM = np.sum(YhatSVM!=YTrain)/n\n",
    "print('Taux erreur SVM =', err_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÉPONSE À LA QUESTION 3.5 :\n",
    "\n",
    "nn = 500\n",
    "X1_min, X1_max = XTrain[:, 0].min() - 0.5, XTrain[:, 0].max() + 0.5\n",
    "X2_min, X2_max = XTrain[:, 1].min() - 0.5, XTrain[:, 1].max() + 0.5\n",
    "XX1, XX2 = np.meshgrid(np.linspace(X1_min, X1_max, nn), np.linspace(X2_min, X2_max, nn))\n",
    "\n",
    "figScatter_new = plt.figure(figsize=(13,6))\n",
    "ax1 = figScatter_new.add_subplot(1,2,1)\n",
    "ax1.scatter(XTrain[np.where(YTrain==-1),0], XTrain[np.where(YTrain==-1),1], color='purple', marker='.', label='Classe -1',s=150)\n",
    "ax1.scatter(XTrain[np.where(YTrain==1),0], XTrain[np.where(YTrain==1),1], color='orange', marker='.', label='Classe 1',s=150)\n",
    "Z_spct = perceptron_predict(W,np.c_[XX1.ravel(), XX2.ravel()])\n",
    "Z_spct = Z_spct.reshape(XX1.shape)\n",
    "out = ax1.contourf(XX1, XX2, Z_spct, alpha=0.2)\n",
    "bound = ax1.contour(XX1, XX2, Z_spct, [0.5], linewidths=2.0, colors=\"blue\")\n",
    "ax1.legend(fontsize=20, loc='upper right')\n",
    "ax1.set_xlabel(\"$X_1$\",fontsize=20)\n",
    "ax1.set_ylabel(\"$X_2$\",fontsize=20)\n",
    "ax1.set_title(\"Perceptron\",fontsize=20)\n",
    "ax1.tick_params(axis='x', labelsize=20)\n",
    "ax1.tick_params(axis='y', labelsize=20)\n",
    "\n",
    "ax2 = figScatter_new.add_subplot(1,2,2)\n",
    "ax2.scatter(XTrain[np.where(YTrain==-1),0], XTrain[np.where(YTrain==-1),1], color='purple', marker='.', label='Classe -1',s=150)\n",
    "ax2.scatter(XTrain[np.where(YTrain==1),0], XTrain[np.where(YTrain==1),1], color='orange', marker='.', label='Classe 1',s=150)\n",
    "Z_SVM = SVMclf.predict(np.c_[XX1.ravel(), XX2.ravel()])\n",
    "Z_SVM = Z_SVM.reshape(XX1.shape)\n",
    "out = ax2.contourf(XX1, XX2, Z_SVM, alpha=0.2)\n",
    "bound = ax2.contour(XX1, XX2, Z_SVM, [0.5], linewidths=2.0, colors=\"blue\")\n",
    "ax2.legend(fontsize=20, loc='upper right')\n",
    "ax2.set_xlabel(\"$X_1$\",fontsize=20)\n",
    "ax2.set_ylabel(\"$X_2$\",fontsize=20)\n",
    "ax2.set_title(\"SVM\",fontsize=20)\n",
    "ax2.tick_params(axis='x', labelsize=20)\n",
    "ax2.tick_params(axis='y', labelsize=20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.  Lorsque les classes ne sont pas parfaitement séparables ?\n",
    "\n",
    "On considère maintenant que chaque observation $i \\in \\{1,\\dots,n\\}$, $X_i = [X_{i1},X_{i2}]$ sera générée de la façon suivante\n",
    "\n",
    "\\begin{equation}\n",
    "X_i \\sim \\mathcal{N}\\left(\\mu_1, \\Sigma_1 \\right) \\; \\text{si} \\; Y_i = -1 \\quad\\quad \\text{et} \\quad\\quad  X_i \\sim \\mathcal{N}\\left(\\mu_2, \\Sigma_2 \\right) \\; \\text{si} \\; Y_i = 1.\n",
    "\\end{equation}\n",
    "où\n",
    "\\begin{equation}\n",
    "    \\mu_1 = [0, 0], \\quad \\mu_2 = [0, 4], \\quad \n",
    "    \\Sigma_1 = \\begin{bmatrix}\n",
    "             2 & 1 \\\\ \n",
    "             1 & 3\n",
    "            \\end{bmatrix}, \\quad \n",
    "    \\Sigma_2 = \\begin{bmatrix}\n",
    "             6 & -3 \\\\ \n",
    "             -3 & 3.5\n",
    "            \\end{bmatrix},  \n",
    "\\end{equation}\n",
    "\n",
    "**Question 4.1.** À l'aide du TD4, représenter le scatter plot de cette base de données.\n",
    "\n",
    "**Question 4.2.** Calibrer le classifieur Perceptron sur cette base de données simulée et tracer la convergence du taux d'erreur en fonction des itérations. Que pouvons nous observer ?\n",
    "\n",
    "**Question 4.3.** Calibrer le classifieur SVM sur cette base de données simulée et calculer le taux d'erreur global.\n",
    "\n",
    "**Question 4.3.** Afficher sur le scatter plot les frontières de décision obtenues par ces deux classifieurs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÉPONSE À LA QUESTION 4.1 :\n",
    "np.random.seed(407)\n",
    "\n",
    "n1 = 100 \n",
    "n2 = 100\n",
    "n = n1+n2\n",
    "mu1 = [0, 0]\n",
    "mu2 = [0, 4]\n",
    "Cov1 = np.array([[2, 1], [1, 3]])\n",
    "Cov2 = np.array([[6, -3], [-3, 3.5]])\n",
    "rng = np.random.default_rng()\n",
    "XTrain_new = np.r_[rng.multivariate_normal(mu1, Cov1, size=n1), rng.multivariate_normal(mu2, Cov2, size=n2)]\n",
    "YTrain_new = np.r_[-np.ones((n1,1)), np.ones((n2,1))].ravel()\n",
    "\n",
    "X1_min, X1_max = XTrain_new[:, 0].min() - 0.5, XTrain_new[:, 0].max() + 0.5\n",
    "X2_min, X2_max = XTrain_new[:, 1].min() - 0.5, XTrain_new[:, 1].max() + 0.5\n",
    "\n",
    "figScatter = plt.figure(figsize=(6,6))\n",
    "ax1 = figScatter.add_subplot(1,1,1)\n",
    "ax1.scatter(XTrain_new[np.where(YTrain_new==-1),0], XTrain_new[np.where(YTrain_new==-1),1], color='purple', marker='.', label='C1',s=150)\n",
    "ax1.scatter(XTrain_new[np.where(YTrain_new==1),0], XTrain_new[np.where(YTrain_new==1),1], color='orange', marker='.', label='C2',s=150)\n",
    "ax1.legend(fontsize=20, loc='upper right')\n",
    "ax1.set_xlabel(\"$X_1$\",fontsize=20)\n",
    "ax1.set_ylabel(\"$X_2$\",fontsize=20)\n",
    "ax1.set_title(\"Scatter plot of the Training set\",fontsize=20)\n",
    "ax1.set_xlim([X1_min,X1_max])\n",
    "ax1.set_ylim([X2_min,X2_max])\n",
    "ax1.tick_params(axis='x', labelsize=20)\n",
    "ax1.tick_params(axis='y', labelsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÉPONSE À LA QUESTION 4.2 :\n",
    "W_new, stock_err = fit_perceptron(XTrain_new,YTrain_new,6)\n",
    "figConv = plt.figure(figsize=(6,6))\n",
    "ax1 = figConv.add_subplot(1,1,1)\n",
    "ax1.plot(stock_err)\n",
    "ax1.set_ylim([0,1])\n",
    "#ax1.set_yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÉPONSE À LA QUESTION 4.3 :\n",
    "SVMclf = svm.SVC(kernel='linear')\n",
    "SVMclf.fit(XTrain_new, YTrain_new)\n",
    "YhatSVM = SVMclf.predict(XTrain_new)\n",
    "err_SVM = np.sum(YhatSVM!=YTrain_new)/n\n",
    "print('Taux erreur SVM =', err_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÉPONSE À LA QUESTION 4.4 :\n",
    "\n",
    "nn = 500\n",
    "X1_min, X1_max = XTrain_new[:, 0].min() - 0.5, XTrain_new[:, 0].max() + 0.5\n",
    "X2_min, X2_max = XTrain_new[:, 1].min() - 0.5, XTrain_new[:, 1].max() + 0.5\n",
    "XX1_new, XX2_new = np.meshgrid(np.linspace(X1_min, X1_max, nn), np.linspace(X2_min, X2_max, nn))\n",
    "Z_spct = perceptron_predict(W_new,np.c_[XX1_new.ravel(), XX2_new.ravel()])\n",
    "Z_spct = Z_spct.reshape(XX1_new.shape)\n",
    "\n",
    "figScatter_new = plt.figure(figsize=(13,6))\n",
    "ax1_new = figScatter_new.add_subplot(1,2,1)\n",
    "out = ax1_new.contourf(XX1_new, XX2_new, Z_spct, alpha=0.2)\n",
    "bound = ax1_new.contour(XX1_new, XX2_new, Z_spct, [0.5], linewidths=2.0, colors=\"blue\")\n",
    "ax1_new.scatter(XTrain_new[np.where(YTrain_new==-1),0], XTrain_new[np.where(YTrain_new==-1),1], color='purple', marker='.', label='Classe -1',s=150)\n",
    "ax1_new.scatter(XTrain_new[np.where(YTrain_new==1),0], XTrain_new[np.where(YTrain_new==1),1], color='orange', marker='.', label='Classe 1',s=150)\n",
    "ax1_new.legend(fontsize=20, loc='upper right')\n",
    "ax1_new.set_xlabel(\"$X_1$\",fontsize=20)\n",
    "ax1_new.set_ylabel(\"$X_2$\",fontsize=20)\n",
    "ax1_new.set_title(\"Perceptron\",fontsize=20)\n",
    "ax1_new.set_xlim([X1_min,X1_max])\n",
    "ax1_new.set_ylim([X2_min,X2_max])\n",
    "ax1_new.tick_params(axis='x', labelsize=20)\n",
    "ax1_new.tick_params(axis='y', labelsize=20)\n",
    "\n",
    "ax2_new = figScatter_new.add_subplot(1,2,2)\n",
    "ax2_new.scatter(XTrain_new[np.where(YTrain_new==-1),0], XTrain_new[np.where(YTrain_new==-1),1], color='purple', marker='.', label='Classe -1',s=150)\n",
    "ax2_new.scatter(XTrain_new[np.where(YTrain_new==1),0], XTrain_new[np.where(YTrain_new==1),1], color='orange', marker='.', label='Classe 1',s=150)\n",
    "Z_SVM = SVMclf.predict(np.c_[XX1_new.ravel(), XX2_new.ravel()])\n",
    "Z_SVM = Z_SVM.reshape(XX1_new.shape)\n",
    "out = ax2_new.contourf(XX1_new, XX2_new, Z_SVM, alpha=0.2)\n",
    "bound = ax2_new.contour(XX1_new, XX2_new, Z_SVM, [0.5], linewidths=2.0, colors=\"blue\")\n",
    "ax2_new.legend(fontsize=20, loc='upper right')\n",
    "ax2_new.set_xlabel(\"$X_1$\",fontsize=20)\n",
    "ax2_new.set_ylabel(\"$X_2$\",fontsize=20)\n",
    "ax2_new.set_title(\"SVM\",fontsize=20)\n",
    "ax2_new.tick_params(axis='x', labelsize=20)\n",
    "ax2_new.tick_params(axis='y', labelsize=20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
