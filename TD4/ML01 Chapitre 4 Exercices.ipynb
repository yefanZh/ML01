{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML01 : TD4 - Classifieurs génératifs pour mixtures gaussiennes multivariées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Génération de la base d'apprentissage par gaussiennes multivariées\n",
    "\n",
    "L'objectif de cette section est de générer une base d'apprentissage à partir d'un modèle de mixture gaussiennes multivariées.\n",
    "- On se placera dans un contexte où l'on dispose de $d=2$ variables aléatoires descrptives et $K=2$ classes à prédire.\n",
    "- On générera $n=1000$ observations telles que $n_1 = 500$ observations appartiendront à la classe 1 et $n_2 = 500$ observations à la classe 2.\n",
    "- Pour chaque observation $i \\in \\{1,\\dots,n\\}$, $Y^{(i)}$ caractérisera la variable aléatoire décrivant la classe de l'observation $i$.\n",
    "- Pour chaque observation $i \\in \\{1,\\dots,n\\}$, $X^{(i)} = \\left[X_{1}^{(i)},X_{2}^{(i)}\\right]$ caractérisera le vecteur aléatoire décrivant le profile de l'observation $i$, tel que :\n",
    "\n",
    "    \\begin{equation}\n",
    "    X^{(i)} \\sim \\mathcal{N}\\left(\\mu^{(1)}, \\Sigma^{(1)} \\right) \\; \\text{si} \\; Y^{(i)} = 1 \\quad\\quad \\text{et} \\quad\\quad  X^{(i)} \\sim \\mathcal{N}\\left(\\mu^{(2)}, \\Sigma^{(2)} \\right) \\; \\text{si} \\; Y^{(i)} = 2.\n",
    "    \\end{equation}\n",
    "\n",
    "- On définira pour la suite :\n",
    "\n",
    "    \\begin{equation}\n",
    "        \\mu^{(1)} = [0, 0], \\quad \\mu^{(2)} = [0, 4], \\quad \n",
    "        \\Sigma^{(1)} = \\Sigma^{(2)} = \\Sigma = \\begin{bmatrix}\n",
    "                 2 & 1 \\\\ \n",
    "                 1 & 3\n",
    "                \\end{bmatrix}.\n",
    "    \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.** Générer une base d'apprentissage $\\{YTrain, XTrain\\}$ selon le modèle introduit ci-dessus. Pour cela, on pourra utiliser la fonction `rng.multivariate_normal` de `np.random.default_rng()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÉPONSE À LA QUESTION 1.1 :\n",
    "np.random.seed(407)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2.** Puisque l'on a $d=2$ variables descriptives, on peut représenter les nuages 2 points sur une figure 2D. Représenter les 2 nuages de points (scatter plot) de sorte à bien visualiser les observations de la classe 1 et celles de la classe 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÉPONSE À LA QUESTION 1.2 :\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classifieurs LDA, QDA, Naive Bayes par Scikit-Learn\n",
    "\n",
    "L'objectif de cette section est de calibrer et comparer les 3 classifieurs génératifs que nous avons étudiés depuis le début du cours, c'est à dire : Classifieur de Bayes Naïf, Quadratic Discriminant Analysis (QDA) et Linear Discriminant Analysis (LDA). Pour cela, nous ultiliserons les fonctions déjà implémentées par Scikit-Learn.\n",
    "Vous trouverez plus d'informations concernant ces fonctions sur les pages suivantes :\n",
    "- Classifieur de Bayes Naïf : https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "- Quadratic Discriminant Analysis : https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis\n",
    "- Linear Discriminant Analysis : https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html#sklearn.discriminant_analysis.LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1.** Calibrer les classifieurs Naive Bayes, LDA et QDA sur la base d'apprentissage générée dans la section précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÉPONSE À LA QUESTION 2.1 :\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.** On souhaite maintenant comparer le taux d'erreurs global de chaque classifieurs sur cette base d'apprentissage. Calculer et comparer les taux d'erreurs globaux des classifieurs empiriques Naive Bayes, LDA et QDA sur la base d'apprentissage. Comment peut-on expliquer ce résultat ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÉPONSE À LA QUESTION 2.2 :\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.** Afficher les frontières de décision de chaque classifieur sur 3 subplots. Pour cela on pourra s'aider de la page Scikit-Learn suivante : https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÉPONSE À LA QUESTION 2.3 :\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Lorsque les matrices de covariances diffèrent par classe\n",
    "\n",
    "L'objectif de cette section est de générer une nouvelle base d'apprentissage avec les prarmètres suivant :\n",
    "\n",
    "\\begin{equation}\n",
    "    \\mu^{(1)} = [0, 0], \\quad \\mu^{(2)} = [0, 4], \\quad \n",
    "    \\Sigma^{(1)} = \\begin{bmatrix}\n",
    "             2 & 1 \\\\ \n",
    "             1 & 3\n",
    "            \\end{bmatrix}, \\quad \n",
    "    \\Sigma^{(2)} = \\begin{bmatrix}\n",
    "             6 & -3 \\\\ \n",
    "             -3 & 3.5\n",
    "            \\end{bmatrix}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.** En reprenant le code de la section 1, génerer une nouvelle base d'apprentissage avec ces nouveaux paramètres et afficher le scatter plot associé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÉPONSE À LA QUESTION 3.1 :\n",
    "np.random.seed(407)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2.** Calibrer les classifieurs Naive Bayes, LDA et QDA sur cette nouvelle base d'apprentissage et calculer leur taux d'erreurs respectifs sur la base d'apprentissage (reprendre le même code que dans la section 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÉPONSE À LA QUESTION 3.2 :\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3.** Afficher les forntières de décision de chaque classifieur sur cette nouvelle base de données (en réutilisant les mêmes codes que dans la section 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RÉPONSE À LA QUESTION 3.2 :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
